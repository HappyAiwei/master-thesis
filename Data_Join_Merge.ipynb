{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geoplot as gplt\n",
    "import shapefile\n",
    "import osr\n",
    "import dbf\n",
    "import requests\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countypairs = pd.read_csv('/home/jinli/PycharmProjects/county-pair-list.txt')\n",
    "countypairs.drop_duplicates(subset='COUNTYPAIR_ID', inplace = True)\n",
    "\n",
    "new = countypairs['COUNTYPAIR_ID'].str.split(\"-\", n = 1, expand = True)\n",
    "\n",
    "pairid = pd.concat([new[0], new[1]], ignore_index=True)\n",
    "pairid = pairid.drop_duplicates()\n",
    "pairid = pairid.to_frame('id')\n",
    "pairid = pairid[~pairid['id'].isin(['06001', '06041', '06081','06075'])] ### county fips changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAUS data (Unemployment Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/home/jinli/Desktop/Thesis/Data/LAU(unemployment_rate)/*.csv')\n",
    "dfs = [pd.read_csv(file) for file in files]\n",
    "lausdata = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "lausdata['GEOID10'] = lausdata['Series ID'].map(lambda x: x[5:10])\n",
    "lausdata['STATEFP10'] = lausdata['GEOID10'].map(lambda x: x[0:2])\n",
    "lausdata['COUNTYFP10'] = lausdata['GEOID10'].map(lambda x: x[2:])\n",
    "\n",
    "lausdata = pd.merge(pairid, lausdata, how='left', left_on='id', right_on='GEOID10')\n",
    "lausdata = lausdata.dropna()\n",
    "### a = lausdata.GEOID10.unique()\n",
    "### len(a)      1126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lausdata.to_csv('LAUS_COUNTY_MONTHLY_UNEMPLOYMENT.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform monthly LAUS data to quarterly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlaus = pd.read_csv('LAUS_COUNTY_MONTHLY_UNEMPLOYMENT.csv')\n",
    "\n",
    "mlaus['id'] = mlaus['id'].astype(str)\n",
    "mlaus['id'] = mlaus['id'].str.zfill(5)\n",
    "\n",
    "mlaus['Year'] = mlaus['Year'].astype(int)\n",
    "mlaus = mlaus[(mlaus['Year'] > 2005) & (mlaus['Year'] < 2016)]\n",
    "\n",
    "mlaus['Value'] = pd.to_numeric(mlaus['Value'], errors='coerce')\n",
    "mlaus = mlaus.replace(np.nan, 0, regex=True)\n",
    "\n",
    "mlaus['Month'] = mlaus['Period'].str[1:]\n",
    "mlaus['Year-Month'] = pd.to_datetime(mlaus[['Year', 'Month']].assign(Day=1)).dt.to_period('M')\n",
    "mlaus['Qtr'] = pd.to_datetime(mlaus[['Year', 'Month']].assign(Day=1)).dt.quarter\n",
    "\n",
    "mlaus = mlaus[['id', 'Year', 'Qtr', 'Value']]\n",
    "mlaus.sort_values(by =['id', 'Year', 'Qtr'], ignore_index=True, inplace=True)\n",
    "\n",
    "qlaus = mlaus.groupby(['id', 'Year', 'Qtr'])['Value'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlaus.to_csv('LAUS_COUNTY_QUARTERLY_UNEMPLOYMENT.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoPlot: all states, all counties and broder counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All counties\n",
    "allcounties = ZipFile('/home/jinli/PycharmProjects/tl_2010_us_county10(NEW).zip', 'r')\n",
    "\n",
    "filenames_ac = [y for y in sorted(allcounties.namelist())\n",
    "                 for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)]\n",
    "\n",
    "dbf_ac, prj_ac, shp_ac, shx_ac = [io.BytesIO(allcounties.read(filename)) for filename in filenames_ac]\n",
    "\n",
    "r_ac = shapefile.Reader(shp=shp_ac, shx=shx_ac, dbf=dbf_ac)\n",
    "## r_ac.numRecords   ### 3221\n",
    "\n",
    "\n",
    "attributes, geometry = [], []\n",
    "\n",
    "field_names = [field[0] for field in r_ac.fields[1:]]\n",
    "\n",
    "for row in r_ac.shapeRecords():\n",
    "    geometry.append(shape(row.shape.__geo_interface__))\n",
    "    attributes.append(dict(zip(field_names,row.record)))\n",
    "    \n",
    "prj = io.TextIOWrapper(prj_ac, encoding='utf-8')\n",
    "proj4 = osr.SpatialReference(prj.read()).ExportToProj4()\n",
    "\n",
    "gdf_ac = gpd.GeoDataFrame(data=attributes, geometry=geometry, crs=proj4)\n",
    "gdf_ac.sort_values(by =['STATEFP10', 'COUNTYFP10'], inplace=True)\n",
    "gdf_ac.reset_index(drop=True, inplace=True)\n",
    "gdf_ac[['INTPTLON10', 'INTPTLAT10']] = gdf_ac[['INTPTLON10', 'INTPTLAT10']].apply(pd.to_numeric)\n",
    "\n",
    "gdf_ac = gdf_ac[(gdf_ac.STATEFP10 != '02') & (gdf_ac.STATEFP10 != '72') & (gdf_ac.STATEFP10 != '15')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All states\n",
    "allstates = ZipFile('/home/jinli/PycharmProjects/tl_2010_us_state10.zip', 'r')\n",
    "\n",
    "filenames_as = [y for y in sorted(allstates.namelist())\n",
    "                for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)]\n",
    "\n",
    "dbf_as, prj_as, shp_as, shx_as = [io.BytesIO(allstates.read(filename)) for filename in filenames_as]\n",
    "\n",
    "r_as = shapefile.Reader(shp=shp_as, shx=shx_as, dbf=dbf_as)\n",
    "\n",
    "attributes, geometry = [], []\n",
    "\n",
    "field_names = [field[0] for field in r_as.fields[1:]]\n",
    "for row in r_as.shapeRecords():\n",
    "    geometry.append(shape(row.shape.__geo_interface__))\n",
    "    attributes.append(dict(zip(field_names,row.record)))\n",
    "    \n",
    "prj = io.TextIOWrapper(prj_as, encoding='utf-8')\n",
    "proj4 = osr.SpatialReference(prj.read()).ExportToProj4()\n",
    "\n",
    "gdf_as = gpd.GeoDataFrame(data=attributes, geometry=geometry, crs=proj4)\n",
    "gdf_as = gdf_as[~gdf_as['STATEFP10'].isin(['02', '72', '15'])]\n",
    "gdf_as.sort_values(by ='STATEFP10', ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_list = lausdata.GEOID10.tolist()\n",
    "cp_list = list(set(cp_list)) ## remove duplicates\n",
    "#cp_list = [e for e in cp_list if e not in ('06001', '06041', '06081','06075')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cp = gdf_ac[gdf_ac['GEOID10'].isin(cp_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50,50))\n",
    "gdf_cp.plot(ax=ax, color='steelblue', edgecolor='none')\n",
    "gdf_ac.plot(ax=ax, facecolor='none', linewidth=0.2, edgecolor='grey')\n",
    "gdf_as.plot(ax=ax, facecolor='none', linewidth=1, edgecolor='black')\n",
    "\n",
    "fig.savefig('full_figure.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCEW (Quarterly Census of Employment and Wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv('Paired_County_ID.csv')\n",
    "ids['id'] = ids['id'].astype(str)\n",
    "ids['id'] = ids['id'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/home/jinli/Desktop/Thesis/Data/QCEW/2005.q1-q4.by_area/*.csv')\n",
    "dfs = [pd.read_csv(file) for file in files]\n",
    "qcewdata = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcewdata05 = qcewdata[qcewdata['area_fips'].apply(lambda x: str(x).isdigit())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcewdata05['area_fips'] = qcewdata05['area_fips'].astype(str)\n",
    "qcewdata05['area_fips'] = qcewdata05['area_fips'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcewdata05 = pd.merge(qcewdata05, ids, how='left', left_on='area_fips', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01001 = pd.read_csv('/home/jinli/Desktop/Thesis/Data/QCEW/2005.q1-q4.by_area/2005.q1-q4 01001 Autauga County, Alabama.csv')\n",
    "df01001['area_fips'] = df01001['area_fips'].astype(str)\n",
    "df01001['area_fips'] = df01001['area_fips'].str.zfill(5)\n",
    "df01001.drop(df01001.columns[21:], axis=1, inplace=True)\n",
    "df01001 = df01001.loc[df01001['own_code']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Benefit Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbe = pd.read_excel('MaxBenefitExtension.xlsx', index_col=0) \n",
    "\n",
    "mbe.drop(columns=['2016Q1', '2016Q2', '2016Q3', '2016Q4'], inplace=True)\n",
    "mbe.reset_index(inplace=True)\n",
    "mbe = mbe.iloc[:, 2:]\n",
    "\n",
    "mbe = mbe.melt(id_vars=['state_id'], ignore_index=True)\n",
    "mbe.fillna(0, inplace=True) \n",
    "mbe['value'] += 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbe.to_csv('Maximum_Benefit_Duration.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  county-pair ids and centroid distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dist = pd.read_csv('CountyPair_Centroid_Border_Distance.csv') ### 1178 entries\n",
    "cp_id = pd.read_csv('Paired_County_ID.csv') ### 1126 entries\n",
    "\n",
    "cp_dist = pd.merge(cp_dist, cp_id, how='left', left_on='GEOID10_FIPS1', right_on='id')  \n",
    "cp_dist = pd.merge(cp_dist, cp_id, how='left', left_on='GEOID10_FIPS2', right_on='id')\n",
    "#7   id_x            1166 non-null   float64\n",
    "#8   id_y            1172 non-null   float64\n",
    "cp_dist.dropna(inplace=True)  ### 1163 rows × 9 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: cp_dist and benefit extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbe = pd.read_csv('Maximum_Benefit_Duration.csv')\n",
    "\n",
    "df = pd.merge(cp_dist, mbe, how='outer', left_on='STATE_FIPS1', right_on='state_id') \n",
    "# cp_dist.shape (1163, 9)\n",
    "# mbe.shape (2120, 3)   53*40=2120\n",
    "# df.shape (46680, 12)  1163*40=46520\n",
    "#---  ------          --------------  -----\n",
    "# 1   STATE_FIPS1     46520 non-null  float64\n",
    "# 9   state_id        46680 non-null  int64\n",
    "df.dropna(inplace=True)\n",
    "df.drop(df.columns[7:10], axis=1, inplace=True)\n",
    "df.rename({'variable': 'Period', 'value': 'BenefitDuration1'}, axis=1, inplace=True)\n",
    "df = df[['COUNTYPAIR_ID', 'Period', \n",
    "         'STATE_FIPS1', 'BenefitDuration1', 'GEOID10_FIPS1', 'distance_FIPS1', \n",
    "         'STATE_FIPS2', 'GEOID10_FIPS2', 'distance_FIPS2']]\n",
    "\n",
    "\n",
    "df = pd.merge(df, mbe, left_on=['STATE_FIPS2', 'Period'], right_on=['state_id', 'variable'])\n",
    "df.drop(['variable'], axis=1, inplace=True)\n",
    "df.rename({'value': 'BenefitDuration2'}, axis=1, inplace=True)\n",
    "df = df[['COUNTYPAIR_ID', 'Period', \n",
    "         'STATE_FIPS1', 'BenefitDuration1', 'GEOID10_FIPS1', 'distance_FIPS1', \n",
    "         'STATE_FIPS2', 'BenefitDuration2', 'GEOID10_FIPS2', 'distance_FIPS2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: merging quarterly unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = pd.read_csv('LAUS_COUNTY_QUARTERLY_UNEMPLOYMENT.csv')\n",
    "\n",
    "ur['Period'] = ur.Year.map(str) + 'Q' + ur.Qtr.map(str)\n",
    "ur = ur[['id', 'Period', 'Value']]\n",
    "ur.rename({'Value': 'UR'}, axis=1, inplace=True)\n",
    "\n",
    "df1 = df[['COUNTYPAIR_ID', 'Period', 'STATE_FIPS1', 'BenefitDuration1', 'GEOID10_FIPS1', 'distance_FIPS1']]\n",
    "df2 = df[['COUNTYPAIR_ID', 'Period', 'STATE_FIPS2', 'BenefitDuration2', 'GEOID10_FIPS2', 'distance_FIPS2']]\n",
    "\n",
    "df1 = pd.merge(df1, ur, left_on=['GEOID10_FIPS1', 'Period'], right_on=['id', 'Period'])\n",
    "df2 = pd.merge(df2, ur, left_on=['GEOID10_FIPS2', 'Period'], right_on=['id', 'Period'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: merging QCEW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcew = pd.read_csv('QCEW_QUARTERLY_CENSUS_of_EMPLOYMENT_and_WAGES.csv')\n",
    "\n",
    "qcew['Period'] = qcew.year.map(str) + 'Q' + qcew.qtr.map(str)\n",
    "\n",
    "df1 = pd.merge(df1, qcew, left_on=['GEOID10_FIPS1', 'Period'], right_on=['area_fips', 'Period'])\n",
    "df2 = pd.merge(df2, qcew, left_on=['GEOID10_FIPS2', 'Period'], right_on=['area_fips', 'Period'])\n",
    "\n",
    "df1.drop(['id_x', 'area_fips', 'id_y'], axis=1, inplace=True)\n",
    "df1_1 = df1.iloc[:, 0:6]\n",
    "df1_2 = df1.iloc[:, 6:]\n",
    "df1_2 = df1_2.add_suffix('_1')\n",
    "df1 = pd.concat([df1_1, df1_2], axis=1)\n",
    "\n",
    "df2.drop(['id_x', 'area_fips', 'id_y'], axis=1, inplace=True)\n",
    "df2_1 = df2.iloc[:, 0:6]\n",
    "df2_2 = df2.iloc[:, 6:]\n",
    "df2_2 = df2_2.add_suffix('_2')\n",
    "df2 = pd.concat([df2_1, df2_2], axis=1)\n",
    "\n",
    "df1.sort_values(by =['COUNTYPAIR_ID', 'Period'], inplace=True)\n",
    "df2.sort_values(by =['COUNTYPAIR_ID', 'Period'], inplace=True)\n",
    "\n",
    "df1.to_csv('DataFrame1.csv', index=False)\n",
    "df2.to_csv('DataFrame2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
